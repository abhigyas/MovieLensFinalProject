{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaborative Filtering with Deep Neural Network for Movie Recommendations using PyTorch\n",
    "# Dependencies\n",
    "\n",
    "To run this notebook, you need the following dependencies:\n",
    "\n",
    "- pandas\n",
    "- numpy\n",
    "- torch\n",
    "- scikit-learn\n",
    "- matplotlib\n",
    "- contextlib\n",
    "```bash \n",
    "pip install 'Dependency'\n",
    "```\n",
    "# Installation\n",
    "\n",
    "First, create and activate a Python virtual environment:\n",
    "\n",
    "```bash\n",
    "python -m venv .venv\n",
    "source .venv/bin/activate  # On Windows use: .venv\\Scripts\\activate\n",
    "```\n",
    "\n",
    "# Dataset\n",
    "Ensure the dataset is in the directory where this notebook is located. The dataset files should include in the directory:\n",
    "```bash \n",
    "/databases/ml-latest-small/\n",
    "```\n",
    "- ratings.csv\n",
    "- movies.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error, root_mean_squared_error\n",
    "from collections import defaultdict\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "from contextlib import contextmanager"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MovieLensDataset Class\n",
    "\n",
    "The `MovieLensDataset` class is a custom PyTorch dataset for handling the MovieLens dataset. It inherits from `torch.utils.data.Dataset` and provides the necessary methods to work with the dataset in a PyTorch DataLoader.\n",
    "\n",
    "### Initialization\n",
    "\n",
    "```python\n",
    "def __init__(self, users, movies, ratings):\n",
    "    self.users = users # A list of array of user IDs.\n",
    "    self.movies = movies # movies: A list or array of movie IDs.\n",
    "    self.ratings = ratings # ratings: A list or array of ratings corresponding to the user-movie pairs.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieLensDataset(Dataset):\n",
    "    def __init__(self, users, movies, ratings):\n",
    "        self.users = users\n",
    "        self.movies = movies\n",
    "        self.ratings = ratings\n",
    "    # Returns the total number of user-movie-rating triplets in the dataset.\n",
    "    def __len__(self):\n",
    "        return len(self.users)\n",
    "    '''\n",
    "    Takes an index item and returns a dictionary containing:\n",
    "        users: The user ID at the given index as a PyTorch tensor.\n",
    "        movies: The movie ID at the given index as a PyTorch tensor.\n",
    "        ratings: The rating at the given index as a PyTorch tensor.\n",
    "    '''\n",
    "    def __getitem__(self, item):\n",
    "        return {\n",
    "            \"users\": torch.tensor(self.users[item], dtype=torch.long),\n",
    "            \"movies\": torch.tensor(self.movies[item], dtype=torch.long),\n",
    "            \"ratings\": torch.tensor(self.ratings[item], dtype=torch.float),\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DeepRecommenderSystem Class\n",
    "\n",
    "The `DeepRecommenderSystem` class is a deep learning-based recommender system implemented using PyTorch. This class is designed to predict user ratings for movies based on user and movie embeddings, and a series of fully connected layers.\n",
    "\n",
    "### Arguments\n",
    "\n",
    "- `num_users` (int): The number of unique users in the dataset.\n",
    "- `num_movies` (int): The number of unique movies in the dataset.\n",
    "- `embedding_size` (int, optional): The size of the embedding vectors for users and movies. Default is 128.\n",
    "\n",
    "### Attributes\n",
    "\n",
    "- `user_embedding` (nn.Embedding): Embedding layer for users.\n",
    "- `movie_embedding` (nn.Embedding): Embedding layer for movies.\n",
    "- `layers` (nn.Sequential): A sequential container of deep neural network layers, including fully connected layers, ReLU activations, batch normalization, and dropout.\n",
    "\n",
    "### Methods\n",
    "\n",
    "- `__init__(self, num_users, num_movies, embedding_size=128)`: Initializes the embedding layers and the deep neural network layers. Also applies weight initialization.\n",
    "- `_init_weights(self, module)`: Initializes the weights of the network layers using Xavier uniform initialization.\n",
    "- `forward(self, users, movies)`: Defines the forward pass through the network. It concatenates the user and movie embeddings and passes them through the deep neural network layers to produce the final rating prediction.\n",
    "\n",
    "This class encapsulates the entire model architecture, from embedding layers to the final prediction layer, and includes methods for weight initialization and the forward pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepRecommenderSystem(nn.Module):\n",
    "    \"\"\"\n",
    "    A deep learning-based recommender system using PyTorch.\n",
    "    Args:\n",
    "        num_users (int): The number of unique users in the dataset.\n",
    "        num_movies (int): The number of unique movies in the dataset.\n",
    "        embedding_size (int, optional): The size of the embedding vectors for users and movies. Default is 128.\n",
    "    Attributes:\n",
    "        user_embedding (nn.Embedding): Embedding layer for users.\n",
    "        movie_embedding (nn.Embedding): Embedding layer for movies.\n",
    "        layers (nn.Sequential): A sequential container of deep neural network layers.\n",
    "    Methods:\n",
    "        _init_weights(module): Initializes the weights of the network layers.\n",
    "        forward(users, movies): Forward pass through the network.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_users, num_movies, embedding_size=128):\n",
    "        super(DeepRecommenderSystem, self).__init__()\n",
    "        \n",
    "        # Embedding layers\n",
    "        self.user_embedding = nn.Embedding(num_users, embedding_size)\n",
    "        self.movie_embedding = nn.Embedding(num_movies, embedding_size)\n",
    "        \n",
    "        # Deep Neural Network layers\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(2 * embedding_size, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Dropout(0.3),\n",
    "            \n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Dropout(0.2),\n",
    "            \n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.Dropout(0.2),\n",
    "            \n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.Dropout(0.1),\n",
    "            \n",
    "            nn.Linear(64, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        # Initialize weights\n",
    "        self.apply(self._init_weights)\n",
    "        \n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.xavier_uniform_(module.weight)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "    \n",
    "    def forward(self, users, movies):\n",
    "        user_embedded = self.user_embedding(users)\n",
    "        movie_embedded = self.movie_embedding(movies)\n",
    "        concatenated = torch.cat([user_embedded, movie_embedded], dim=1)\n",
    "        return self.layers(concatenated).squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model Function\n",
    "\n",
    "The `train_model` function is responsible for training a given PyTorch model using the provided training and validation data loaders. It performs the following tasks:\n",
    "\n",
    "### Arguments\n",
    "\n",
    "- `model` (torch.nn.Module): The model to be trained.\n",
    "- `train_loader` (torch.utils.data.DataLoader): DataLoader for the training dataset.\n",
    "- `val_loader` (torch.utils.data.DataLoader): DataLoader for the validation dataset.\n",
    "- `device` (torch.device): The device (CPU or GPU) to perform training on.\n",
    "- `epochs` (int, optional): Number of epochs to train the model. Default is 10.\n",
    "- `lr` (float, optional): Learning rate for the optimizer. Default is 0.001.\n",
    "\n",
    "### Returns\n",
    "\n",
    "- `tuple`: A tuple containing two lists:\n",
    "  - `train_losses` (list of float): List of average training losses for each epoch.\n",
    "  - `val_losses` (list of float): List of average validation losses for each epoch.\n",
    "\n",
    "### Description\n",
    "\n",
    "1. **Initialization**:\n",
    "   - Defines the loss function (`criterion`) as Mean Squared Error Loss.\n",
    "   - Initializes the optimizer (`optimizer`) as Adam with the specified learning rate.\n",
    "   - Sets up a learning rate scheduler (`scheduler`) to reduce the learning rate on plateau.\n",
    "\n",
    "2. **Training Loop**:\n",
    "   - Iterates over the specified number of epochs.\n",
    "   - For each epoch, the model is set to training mode.\n",
    "   - Iterates over the training data loader, performing the following steps for each batch:\n",
    "     - Moves the batch data (users, movies, ratings) to the specified device.\n",
    "     - Performs a forward pass to get predictions.\n",
    "     - Computes the loss and scales predictions to the 0-5 range.\n",
    "     - Performs backpropagation and updates the model parameters.\n",
    "     - Accumulates the total loss and counts the number of batches.\n",
    "     - Prints the average loss for every 100 batches.\n",
    "\n",
    "3. **Validation Loop**:\n",
    "   - After each epoch, the model is set to evaluation mode.\n",
    "   - Iterates over the validation data loader, performing the following steps for each batch:\n",
    "     - Moves the batch data (users, movies, ratings) to the specified device.\n",
    "     - Performs a forward pass to get predictions.\n",
    "     - Computes the loss and accumulates the total validation loss.\n",
    "\n",
    "4. **Learning Rate Scheduling**:\n",
    "   - Adjusts the learning rate based on the validation loss.\n",
    "\n",
    "5. **Model Saving**:\n",
    "   - Saves the model's state if the validation loss improves.\n",
    "\n",
    "6. **Return**:\n",
    "   - Returns the lists of average training and validation losses for each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, device, epochs=10, lr=0.001):\n",
    "    \"\"\"\n",
    "    Trains a given model using the provided training and validation data loaders.\n",
    "    Args:\n",
    "        model (torch.nn.Module): The model to be trained.\n",
    "        train_loader (torch.utils.data.DataLoader): DataLoader for the training dataset.\n",
    "        val_loader (torch.utils.data.DataLoader): DataLoader for the validation dataset.\n",
    "        device (torch.device): The device (CPU or GPU) to perform training on.\n",
    "        epochs (int, optional): Number of epochs to train the model. Default is 10.\n",
    "        lr (float, optional): Learning rate for the optimizer. Default is 0.001.\n",
    "    Returns:\n",
    "        tuple: A tuple containing two lists:\n",
    "            - train_losses (list of float): List of average training losses for each epoch.\n",
    "            - val_losses (list of float): List of average validation losses for each epoch.\n",
    "    \"\"\"\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2)\n",
    "    \n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    best_val_loss = float('inf')\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        batch_count = 0\n",
    "        \n",
    "        for batch_idx, batch in enumerate(train_loader):\n",
    "            users = batch[\"users\"].to(device)\n",
    "            movies = batch[\"movies\"].to(device)\n",
    "            ratings = batch[\"ratings\"].to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            predictions = model(users, movies)\n",
    "            loss = criterion(predictions * 5.0, ratings)  # Scale predictions to 0-5 range\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            batch_count += 1\n",
    "            \n",
    "            if batch_idx % 100 == 0:\n",
    "                avg_loss = total_loss / batch_count\n",
    "                sys.stderr.write(f\"\\rEpoch {epoch+1}/{epochs} | Batch {batch_idx}/{len(train_loader)} | Avg Loss: {avg_loss:.6f}\")\n",
    "                sys.stderr.flush()\n",
    "        \n",
    "        avg_train_loss = total_loss / batch_count\n",
    "        train_losses.append(avg_train_loss)\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                users = batch[\"users\"].to(device)\n",
    "                movies = batch[\"movies\"].to(device)\n",
    "                ratings = batch[\"ratings\"].to(device)\n",
    "                \n",
    "                predictions = model(users, movies)\n",
    "                loss = criterion(predictions * 5.0, ratings)\n",
    "                val_loss += loss.item()\n",
    "        \n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        val_losses.append(avg_val_loss)\n",
    "        \n",
    "        # Learning rate scheduling\n",
    "        scheduler.step(avg_val_loss)\n",
    "        \n",
    "        print(f\"\\nEpoch {epoch+1}/{epochs} - Train Loss: {avg_train_loss:.6f} - Val Loss: {avg_val_loss:.6f}\")\n",
    "        \n",
    "        # Save best model\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "    \n",
    "    return train_losses, val_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate NDCG Function\n",
    "\n",
    "The `calculate_ndcg` function computes the Normalized Discounted Cumulative Gain (NDCG) at a specified rank `k` for a list of true and predicted ratings. NDCG is a measure of ranking quality that accounts for the position of relevant items in the predicted ranking.\n",
    "\n",
    "### Arguments\n",
    "\n",
    "- `true_ratings` (list of float): List of true ratings.\n",
    "- `predicted_ratings` (list of float): List of predicted ratings.\n",
    "- `k` (int, optional): Number of items to consider for the calculation. Default is 10.\n",
    "\n",
    "### Returns\n",
    "\n",
    "- `ndcg` (float): The NDCG score at rank `k`.\n",
    "\n",
    "### Description\n",
    "\n",
    "1. **Sort Predictions**:\n",
    "   - Sorts the predicted ratings in descending order and retrieves the indices of the top `k` items.\n",
    "\n",
    "2. **Calculate DCG (Discounted Cumulative Gain)**:\n",
    "   - Initializes `dcg` to 0.\n",
    "   - Iterates over the top `k` indices of the sorted predictions.\n",
    "   - For each index, retrieves the corresponding true rating (`rel`).\n",
    "   - Updates `dcg` using the formula: \\((2^{\\text{rel}} - 1) / \\log_2(i + 2)\\), where `i` is the position in the sorted list (starting from 0).\n",
    "\n",
    "3. **Calculate IDCG (Ideal Discounted Cumulative Gain)**:\n",
    "   - Sorts the true ratings in descending order and retrieves the indices of the top `k` items.\n",
    "   - Initializes `idcg` to 0.\n",
    "   - Iterates over the top `k` indices of the sorted true ratings.\n",
    "   - For each index, retrieves the corresponding true rating (`rel`).\n",
    "   - Updates `idcg` using the same formula as for `dcg`.\n",
    "\n",
    "4. **Calculate NDCG**:\n",
    "   - Computes the NDCG score as the ratio of `dcg` to `idcg`.\n",
    "   - If `idcg` is greater than 0, returns the computed NDCG score; otherwise, returns 0.\n",
    "\n",
    "This function provides a way to evaluate the quality of the predicted rankings by comparing them to the ideal rankings based on true ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ndcg(true_ratings, predicted_ratings, k=10):\n",
    "    # Calculate NDCG@k for a list of predictions\n",
    "    \n",
    "    # Args:\n",
    "    #     true_ratings: List of true ratings\n",
    "    #     predicted_ratings: List of predicted ratings\n",
    "    #     k: Number of items to consider\n",
    "    # Sort predictions and get top k indices\n",
    "    top_k_indices = np.argsort(predicted_ratings)[-k:][::-1]\n",
    "    \n",
    "    # Get DCG\n",
    "    dcg = 0\n",
    "    for i, idx in enumerate(top_k_indices):\n",
    "        rel = true_ratings[idx]\n",
    "        dcg += (2**rel - 1) / np.log2(i + 2)  # i+2 because i starts from 0\n",
    "    \n",
    "    # Get IDCG (sort true ratings in descending order)\n",
    "    ideal_order = np.argsort(true_ratings)[-k:][::-1]\n",
    "    idcg = 0\n",
    "    for i, idx in enumerate(ideal_order):\n",
    "        rel = true_ratings[idx]\n",
    "        idcg += (2**rel - 1) / np.log2(i + 2)\n",
    "    \n",
    "    # Calculate NDCG\n",
    "    ndcg = dcg / idcg if idcg > 0 else 0\n",
    "    return ndcg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Metrics Function\n",
    "\n",
    "The `calculate_metrics` function evaluates a trained model on a validation dataset and computes various evaluation metrics. These metrics help in understanding the performance of the model in terms of prediction accuracy and ranking quality.\n",
    "\n",
    "### Arguments\n",
    "\n",
    "- `model` (torch.nn.Module): The trained model to evaluate.\n",
    "- `val_loader` (torch.utils.data.DataLoader): DataLoader for the validation dataset.\n",
    "- `device` (torch.device): The device (CPU or GPU) to perform computations on.\n",
    "\n",
    "### Returns\n",
    "\n",
    "- `tuple`: A tuple containing the following metrics:\n",
    "  - `rmse` (float): Root Mean Squared Error of the predictions.\n",
    "  - `avg_precision` (float): Average precision across all users.\n",
    "  - `avg_recall` (float): Average recall across all users.\n",
    "  - `f_measure` (float): F-measure (harmonic mean of precision and recall).\n",
    "  - `avg_ndcg` (float): Average Normalized Discounted Cumulative Gain across all users.\n",
    "\n",
    "### Description\n",
    "\n",
    "1. **Initialization**:\n",
    "   - Sets the model to evaluation mode.\n",
    "   - Initializes lists to store predictions and actual ratings.\n",
    "   - Initializes dictionaries to store user-specific predictions and actual items.\n",
    "\n",
    "2. **Prediction Loop**:\n",
    "   - Iterates over the validation data loader.\n",
    "   - For each batch, moves the data (users, movies, ratings) to the specified device.\n",
    "   - Performs a forward pass to get predictions and scales them back to the 0-5 range.\n",
    "   - Extends the predictions and actuals lists with the batch results.\n",
    "   - Stores both predicted and true ratings for each user-movie pair.\n",
    "\n",
    "3. **Calculate RMSE**:\n",
    "   - Computes the Root Mean Squared Error (RMSE) between the actual and predicted ratings.\n",
    "\n",
    "4. **Calculate Precision and Recall**:\n",
    "   - Initializes lists to store precision and recall for each user.\n",
    "   - For each user, sorts the recommendations by predicted rating.\n",
    "   - Extracts the recommended movie IDs.\n",
    "   - Calculates precision and recall for the top `k` recommendations.\n",
    "   - Computes the average precision and recall across all users.\n",
    "\n",
    "5. **Calculate F-measure**:\n",
    "   - Computes the F-measure as the harmonic mean of average precision and recall.\n",
    "\n",
    "6. **Calculate NDCG**:\n",
    "   - Initializes a list to store NDCG scores for each user.\n",
    "   - For each user, sorts the recommendations by predicted rating.\n",
    "   - Aligns the predicted and true ratings for the top `k` recommendations.\n",
    "   - Computes the NDCG score for the user.\n",
    "   - Computes the average NDCG score across all users.\n",
    "\n",
    "7. **Return**:\n",
    "   - Returns the computed metrics: RMSE, average precision, average recall, F-measure, and average NDCG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(model, val_loader, device):\n",
    "    \"\"\"\n",
    "    Calculate various evaluation metrics for a given model on a validation dataset.\n",
    "    Args:\n",
    "        model (torch.nn.Module): The trained model to evaluate.\n",
    "        val_loader (torch.utils.data.DataLoader): DataLoader for the validation dataset.\n",
    "        device (torch.device): The device (CPU or GPU) to perform computations on.\n",
    "    Returns:\n",
    "        tuple: A tuple containing the following metrics:\n",
    "            - rmse (float): Root Mean Squared Error of the predictions.\n",
    "            - avg_precision (float): Average precision across all users.\n",
    "            - avg_recall (float): Average recall across all users.\n",
    "            - f_measure (float): F-measure (harmonic mean of precision and recall).\n",
    "            - avg_ndcg (float): Average Normalized Discounted Cumulative Gain across all users.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    actuals = []\n",
    "    \n",
    "    # Store user-specific predictions and actual items\n",
    "    user_test_items = defaultdict(set)\n",
    "    user_recommendations = defaultdict(list)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            users = batch[\"users\"].to(device)\n",
    "            movies = batch[\"movies\"].to(device)\n",
    "            ratings = batch[\"ratings\"].to(device)\n",
    "            \n",
    "            output = model(users, movies)\n",
    "            scaled_output = output * 5.0  # Scale back to 0-5 range\n",
    "            \n",
    "            predictions.extend(scaled_output.cpu().numpy())\n",
    "            actuals.extend(ratings.cpu().numpy())\n",
    "            \n",
    "            # Store both predicted and true ratings\n",
    "            for user, movie, pred, true in zip(users.cpu().numpy(), \n",
    "                                             movies.cpu().numpy(),\n",
    "                                             scaled_output.cpu().numpy(),\n",
    "                                             ratings.cpu().numpy()):\n",
    "                user_test_items[user].add(movie)\n",
    "                user_recommendations[user].append((movie, pred, true))\n",
    "    \n",
    "    # Calculate RMSE\n",
    "    rmse = root_mean_squared_error(actuals, predictions)\n",
    "    \n",
    "    # Calculate Precision and Recall for each user\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    \n",
    "    for user_id in user_test_items.keys():\n",
    "        # Sort recommendations by predicted rating\n",
    "        user_recs = user_recommendations[user_id]\n",
    "        user_recs.sort(key=lambda x: x[1], reverse=True)\n",
    "        recommended_items = [item[0] for item in user_recs]  # Get just the movie IDs\n",
    "        \n",
    "        # Calculate precision and recall\n",
    "        p, r = calculate_precision_recall(\n",
    "            user_id=user_id,\n",
    "            test_items=user_test_items[user_id],\n",
    "            recommended_items=recommended_items,\n",
    "            k=10\n",
    "        )\n",
    "        precisions.append(p)\n",
    "        recalls.append(r)\n",
    "    \n",
    "    avg_precision = np.mean(precisions)\n",
    "    avg_recall = np.mean(recalls)\n",
    "    \n",
    "    # Calculate F-measure\n",
    "    f_measure = 2 * avg_precision * avg_recall / (avg_precision + avg_recall) if (avg_precision + avg_recall) > 0 else 0\n",
    "    \n",
    "    ndcg_scores = []\n",
    "    for user_id in user_test_items.keys():\n",
    "        user_recs = user_recommendations[user_id]\n",
    "        # Sort by predicted ratings\n",
    "        user_recs.sort(key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        # Get aligned predicted and true ratings\n",
    "        pred_ratings = np.array([pred for _, pred, _ in user_recs[:10]])\n",
    "        true_ratings = np.array([true for _, _, true in user_recs[:10]])\n",
    "        \n",
    "        ndcg = calculate_ndcg(true_ratings, pred_ratings, k=10)\n",
    "        ndcg_scores.append(ndcg)\n",
    "    \n",
    "    avg_ndcg = np.mean(ndcg_scores)\n",
    "    \n",
    "    return rmse, avg_precision, avg_recall, f_measure, avg_ndcg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Precision and Recall Function\n",
    "\n",
    "The `calculate_precision_recall` function computes the precision and recall for a given user based on the recommended items and the actual items in the test set. These metrics help in evaluating the effectiveness of the recommendation system.\n",
    "\n",
    "### Arguments\n",
    "\n",
    "- `user_id` (int): The user ID.\n",
    "- `test_items` (set): Set of items in the test set for this user.\n",
    "- `recommended_items` (list): List of recommended items (top-10).\n",
    "- `k` (int, optional): Number of recommendations to consider. Default is 10.\n",
    "\n",
    "### Returns\n",
    "\n",
    "- `precision` (float): The precision of the recommendations.\n",
    "- `recall` (float): The recall of the recommendations.\n",
    "\n",
    "### Description\n",
    "\n",
    "1. **Select Top-k Recommendations**:\n",
    "   - Takes only the first `k` items from the list of recommended items.\n",
    "\n",
    "2. **Count Hits**:\n",
    "   - Counts how many of the recommended items are present in the test set by computing the intersection of the recommended items and the test items.\n",
    "\n",
    "3. **Calculate Precision**:\n",
    "   - Computes precision as the ratio of hits to `k`. Precision measures the proportion of recommended items that are relevant.\n",
    "\n",
    "4. **Calculate Recall**:\n",
    "   - Computes recall as the ratio of hits to the total number of test items. Recall measures the proportion of relevant items that are recommended.\n",
    "\n",
    "5. **Return**:\n",
    "   - Returns the computed precision and recall values.\n",
    "\n",
    "This function provides a way to evaluate the recommendation system's performance by measuring how many of the recommended items are relevant (precision) and how many of the relevant items are recommended (recall)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_precision_recall(user_id, test_items, recommended_items, k=10):\n",
    "    # Args:\n",
    "    #     user_id: The user ID\n",
    "    #     test_items: Set of items in test set for this user\n",
    "    #     recommended_items: List of recommended items (top-10)\n",
    "    #     k: Number of recommendations to consider (10)\n",
    "\n",
    "    # Take only first k recommendations\n",
    "    recommended_k = recommended_items[:k]\n",
    "    \n",
    "    # Count how many recommended items are in test set\n",
    "    hits = len(set(recommended_k) & set(test_items))\n",
    "    \n",
    "    # Precision = hits / k\n",
    "    precision = hits / k if k > 0 else 0\n",
    "    \n",
    "    # Recall = hits / total test items\n",
    "    recall = hits / len(test_items) if test_items else 0\n",
    "    \n",
    "    return precision, recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommend Movies Function\n",
    "\n",
    "The `recommend_movies` function generates movie recommendations for a given user using a trained model. It predicts ratings for all movies and selects the top `k` recommendations.\n",
    "\n",
    "### Arguments\n",
    "\n",
    "- `model` (torch.nn.Module): Trained model.\n",
    "- `user_id` (int): User ID (encoded).\n",
    "- `movie_ids` (list of int): List of encoded movie IDs.\n",
    "- `df_movies` (pandas.DataFrame): Original movies dataframe.\n",
    "- `device` (torch.device): The device (CPU or GPU) to perform computations on.\n",
    "- `movie_encoder` (LabelEncoder): LabelEncoder used for movie IDs.\n",
    "- `top_k` (int, optional): Number of recommendations to return. Default is 10.\n",
    "\n",
    "### Returns\n",
    "\n",
    "- `recommended_movies` (list of dict): List of top `k` recommended movies with their titles and predicted ratings.\n",
    "\n",
    "### Description\n",
    "\n",
    "1. **Set Model to Evaluation Mode**:\n",
    "   - Sets the model to evaluation mode to disable dropout and batch normalization layers.\n",
    "\n",
    "2. **Create Tensors for Prediction**:\n",
    "   - Creates tensors for the user and movie IDs. The user tensor contains the user ID repeated for each movie ID.\n",
    "\n",
    "3. **Predict Ratings**:\n",
    "   - Performs a forward pass through the model to get predicted ratings for all movies.\n",
    "   - Scales the predicted ratings to the 0-5 range.\n",
    "\n",
    "4. **Create Movie Recommendations**:\n",
    "   - Zips the movie IDs with their predicted ratings.\n",
    "   - Sorts the movies by predicted rating in descending order.\n",
    "   - Selects the top `k` movies.\n",
    "\n",
    "5. **Get Movie Details**:\n",
    "   - Converts the encoded movie IDs back to their original IDs using the `movie_encoder`.\n",
    "   - Retrieves the movie details (title) from the `df_movies` dataframe.\n",
    "   - Appends the movie title and predicted rating to the list of recommended movies.\n",
    "\n",
    "6. **Return**:\n",
    "   - Returns the list of top `k` recommended movies with their titles and predicted ratings.\n",
    "\n",
    "This function provides a way to generate personalized movie recommendations for a user based on the trained model's predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_movies(model, user_id, movie_ids, df_movies, device, movie_encoder, top_k=10):\n",
    "    # Recommend movies for a user\n",
    "    # Args:\n",
    "    #     model: Trained model\n",
    "    #     user_id: User ID (encoded)\n",
    "    #     movie_ids: List of encoded movie IDs\n",
    "    #     df_movies: Original movies dataframe\n",
    "    #     device: torch device\n",
    "    #     movie_encoder: LabelEncoder used for movie IDs\n",
    "    #     top_k: Number of recommendations to return\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    # Create tensors for prediction\n",
    "    user_tensor = torch.tensor([user_id] * len(movie_ids), dtype=torch.long).to(device)\n",
    "    movie_tensor = torch.tensor(movie_ids, dtype=torch.long).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        predictions = model(user_tensor, movie_tensor)\n",
    "        predictions = predictions.cpu().numpy() * 5.0  # Scale to 0-5 range\n",
    "    \n",
    "    # Create movie recommendations\n",
    "    movie_preds = list(zip(movie_ids, predictions))\n",
    "    movie_preds.sort(key=lambda x: x[1], reverse=True)\n",
    "    top_movies = movie_preds[:top_k]\n",
    "    \n",
    "    # Get movie details\n",
    "    recommended_movies = []\n",
    "    for encoded_movie_id, pred_rating in top_movies:\n",
    "        # Convert encoded ID back to original movie ID\n",
    "        original_movie_id = movie_encoder.inverse_transform([encoded_movie_id])[0]\n",
    "        movie_info = df_movies[df_movies['movieId'] == original_movie_id]\n",
    "        if not movie_info.empty:\n",
    "            movie_info = movie_info.iloc[0]\n",
    "            recommended_movies.append({\n",
    "                'title': movie_info['title'],\n",
    "                'predicted_rating': pred_rating\n",
    "            })\n",
    "    \n",
    "    return recommended_movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## stdout_to_file Context Manager\n",
    "\n",
    "The `stdout_to_file` function is a context manager that redirects the standard output (stdout) and standard error (stderr) to both a file and the console. This is useful for logging output to a file while still displaying it in the console.\n",
    "\n",
    "### Arguments\n",
    "\n",
    "- `filename` (str): The name of the file to which stdout and stderr will be redirected.\n",
    "\n",
    "### Description\n",
    "\n",
    "1. **MultiOutputStream Class**:\n",
    "   - A helper class that takes multiple output streams and writes text to all of them.\n",
    "   - `__init__(self, *streams)`: Initializes the class with a list of streams.\n",
    "   - `write(self, text)`: Writes the given text to all streams and flushes them.\n",
    "   - `flush(self)`: Flushes all streams.\n",
    "\n",
    "2. **Context Manager**:\n",
    "   - Opens the specified file in write mode.\n",
    "   - Backs up the current stdout and stderr.\n",
    "   - Creates an instance of `MultiOutputStream` with the file and the original stdout.\n",
    "   - Redirects stdout and stderr to the `MultiOutputStream` instance.\n",
    "   - Yields control back to the caller.\n",
    "   - Restores the original stdout and stderr after the context block is exited.\n",
    "\n",
    "### Usage\n",
    "\n",
    "This context manager can be used to capture and log output from a block of code:\n",
    "\n",
    "```python\n",
    "with stdout_to_file('output.log'):\n",
    "    print(\"This will be logged to both the console and the file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def stdout_to_file(filename):\n",
    "    # Context manager to redirect stdout and stderr to both file and console\n",
    "    class MultiOutputStream:\n",
    "        def __init__(self, *streams):\n",
    "            self.streams = streams\n",
    "\n",
    "        def write(self, text):\n",
    "            for stream in self.streams:\n",
    "                stream.write(text)\n",
    "                stream.flush()\n",
    "\n",
    "        def flush(self):\n",
    "            # Fix: Iterate through streams to flush each one\n",
    "            for stream in self.streams:\n",
    "                stream.flush()\n",
    "\n",
    "    with open(filename, 'w') as file:\n",
    "        stdout_backup = sys.stdout\n",
    "        stderr_backup = sys.stderr\n",
    "        multi_stream = MultiOutputStream(file, sys.stdout)\n",
    "        sys.stdout = multi_stream\n",
    "        sys.stderr = multi_stream\n",
    "        try:\n",
    "            yield\n",
    "        finally:\n",
    "            sys.stdout = stdout_backup\n",
    "            sys.stderr = stderr_backup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Function\n",
    "\n",
    "The `main` function orchestrates the entire process of loading data, training the model, evaluating its performance, and generating movie recommendations. It also redirects the output to both a file and the console using the `stdout_to_file` context manager.\n",
    "\n",
    "### Description\n",
    "\n",
    "1. **Redirect Output**:\n",
    "   - Uses the `stdout_to_file` context manager to redirect stdout and stderr to `small_data_recommendation.txt` and the console.\n",
    "\n",
    "2. **Set Device**:\n",
    "   - Determines whether to use a GPU (if available) or CPU for computations and prints the selected device.\n",
    "\n",
    "3. **Load and Preprocess Data**:\n",
    "   - Loads the ratings and movies data from CSV files.\n",
    "   - Encodes user and movie IDs using `LabelEncoder`.\n",
    "\n",
    "4. **Split Data**:\n",
    "   - Splits the ratings data into training and validation sets using an 80-20 split.\n",
    "\n",
    "5. **Create Datasets**:\n",
    "   - Creates `MovieLensDataset` instances for the training and validation sets.\n",
    "\n",
    "6. **Create DataLoaders**:\n",
    "   - Creates `DataLoader` instances for the training and validation datasets with a batch size of 64.\n",
    "\n",
    "7. **Initialize Model**:\n",
    "   - Initializes the `DeepRecommenderSystem` model with the number of unique users and movies.\n",
    "   - Moves the model to the selected device.\n",
    "\n",
    "8. **Train Model**:\n",
    "   - Trains the model using the `train_model` function and prints the training progress.\n",
    "   - Plots and saves the training and validation loss history.\n",
    "\n",
    "9. **Calculate Metrics**:\n",
    "   - Evaluates the model on the validation set using the `calculate_metrics` function.\n",
    "   - Prints the calculated metrics: RMSE, Precision@10, Recall@10, F-measure, and NDCG@10.\n",
    "\n",
    "10. **Generate Sample Recommendations**:\n",
    "    - Generates movie recommendations for a sample user (user ID 1) using the `recommend_movies` function.\n",
    "    - Prints the top 10 recommended movies with their predicted ratings.\n",
    "\n",
    "This function provides a comprehensive workflow for training and evaluating a deep learning-based recommender system, as well as generating personalized movie recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    with stdout_to_file('small_data_recommendation.txt'):\n",
    "        # Set device\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        print(f\"Using device: {device}\")\n",
    "        \n",
    "        # Load and preprocess data\n",
    "        print(\"Loading data...\")\n",
    "        ratings_df = pd.read_csv(\"databases/ml-latest-small/ratings.csv\")\n",
    "        movies_df = pd.read_csv(\"databases/ml-latest-small/movies.csv\")\n",
    "        \n",
    "        # Encode user and movie IDs\n",
    "        user_encoder = LabelEncoder()\n",
    "        movie_encoder = LabelEncoder()\n",
    "        \n",
    "        ratings_df['userId'] = user_encoder.fit_transform(ratings_df['userId'])\n",
    "        ratings_df['movieId'] = movie_encoder.fit_transform(ratings_df['movieId'])\n",
    "        \n",
    "        # Split data\n",
    "        train_df, val_df = train_test_split(ratings_df, test_size=0.2, random_state=42)\n",
    "        \n",
    "        # Create datasets\n",
    "        train_dataset = MovieLensDataset(\n",
    "            users=train_df.userId.values,\n",
    "            movies=train_df.movieId.values,\n",
    "            ratings=train_df.rating.values\n",
    "        )\n",
    "        \n",
    "        val_dataset = MovieLensDataset(\n",
    "            users=val_df.userId.values,\n",
    "            movies=val_df.movieId.values,\n",
    "            ratings=val_df.rating.values\n",
    "        )\n",
    "        \n",
    "        # Create dataloaders\n",
    "        train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "        \n",
    "        # Initialize model\n",
    "        model = DeepRecommenderSystem(\n",
    "            num_users=len(user_encoder.classes_),\n",
    "            num_movies=len(movie_encoder.classes_)\n",
    "        ).to(device)\n",
    "        \n",
    "        # Train model\n",
    "        print(\"\\nStarting training...\")\n",
    "        train_losses, val_losses = train_model(model, train_loader, val_loader, device)\n",
    "        \n",
    "        # Plot training history\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(train_losses, label='Training Loss')\n",
    "        plt.plot(val_losses, label='Validation Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title('Training History')\n",
    "        plt.legend()\n",
    "        plt.savefig('training_history.png')\n",
    "        plt.close()\n",
    "        \n",
    "        # Calculate metrics\n",
    "        print(\"\\nCalculating metrics...\")\n",
    "        rmse, precision, recall, f_measure, ndcg = calculate_metrics(model, val_loader, device)\n",
    "        print(f\"RMSE: {rmse:.4f}\")\n",
    "        print(f\"Precision@10: {precision:.4f}\")\n",
    "        print(f\"Recall@10: {recall:.4f}\")\n",
    "        print(f\"F-measure: {f_measure:.4f}\")\n",
    "        print(f\"NDCG@10: {ndcg:.4f}\")\n",
    "        \n",
    "        print(\"\\nGenerating sample recommendations...\")\n",
    "        sample_user_id = 1\n",
    "        movie_ids = ratings_df['movieId'].unique()\n",
    "        \n",
    "        # Get recommendations once\n",
    "        recommendations = recommend_movies(model, sample_user_id, movie_ids, movies_df, device, movie_encoder)\n",
    "        \n",
    "        # Print recommendations once in a clear format\n",
    "        print(f\"\\nTop 10 recommended movies for user {sample_user_id}:\")\n",
    "        for i, movie in enumerate(recommendations, 1):\n",
    "            print(f\"{i}. {movie['title']} - Predicted rating: {movie['predicted_rating']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Loading data...\n",
      "\n",
      "Starting training...\n",
      "Epoch 1/10 | Batch 1200/1261 | Avg Loss: 1.183118\n",
      "Epoch 1/10 - Train Loss: 1.172236 - Val Loss: 0.939145\n",
      "Epoch 2/10 | Batch 1200/1261 | Avg Loss: 0.911810\n",
      "Epoch 2/10 - Train Loss: 0.908878 - Val Loss: 0.887655\n",
      "Epoch 3/10 | Batch 1200/1261 | Avg Loss: 0.840216\n",
      "Epoch 3/10 - Train Loss: 0.839532 - Val Loss: 0.846069\n",
      "Epoch 4/10 | Batch 1200/1261 | Avg Loss: 0.780852\n",
      "Epoch 4/10 - Train Loss: 0.779829 - Val Loss: 0.823406\n",
      "Epoch 5/10 | Batch 1200/1261 | Avg Loss: 0.730021\n",
      "Epoch 5/10 - Train Loss: 0.731862 - Val Loss: 0.797402\n",
      "Epoch 6/10 | Batch 1200/1261 | Avg Loss: 0.686446\n",
      "Epoch 6/10 - Train Loss: 0.687753 - Val Loss: 0.795351\n",
      "Epoch 7/10 | Batch 1200/1261 | Avg Loss: 0.654796\n",
      "Epoch 7/10 - Train Loss: 0.657188 - Val Loss: 0.797863\n",
      "Epoch 8/10 | Batch 1200/1261 | Avg Loss: 0.625147\n",
      "Epoch 8/10 - Train Loss: 0.625411 - Val Loss: 0.795235\n",
      "Epoch 9/10 | Batch 1200/1261 | Avg Loss: 0.593791\n",
      "Epoch 9/10 - Train Loss: 0.595570 - Val Loss: 0.792833\n",
      "Epoch 10/10 | Batch 1200/1261 | Avg Loss: 0.567191\n",
      "Epoch 10/10 - Train Loss: 0.569297 - Val Loss: 0.820162\n",
      "\n",
      "Calculating metrics...\n",
      "RMSE: 0.9061\n",
      "Precision@10: 0.8497\n",
      "Recall@10: 0.6362\n",
      "F-measure: 0.7276\n",
      "NDCG@10: 0.8861\n",
      "\n",
      "Generating sample recommendations...\n",
      "\n",
      "Top 10 recommended movies for user 1:\n",
      "1. Paths of Glory (1957) - Predicted rating: 4.50\n",
      "2. Bad Boy Bubby (1993) - Predicted rating: 4.46\n",
      "3. To Catch a Thief (1955) - Predicted rating: 4.43\n",
      "4. Adam's Rib (1949) - Predicted rating: 4.43\n",
      "5. Town Called Panic, A (Panique au village) (2009) - Predicted rating: 4.43\n",
      "6. Wings of the Dove, The (1997) - Predicted rating: 4.43\n",
      "7. Wild Parrots of Telegraph Hill, The (2003) - Predicted rating: 4.42\n",
      "8. Gloomy Sunday (Ein Lied von Liebe und Tod) (1999) - Predicted rating: 4.42\n",
      "9. Fight Club (1999) - Predicted rating: 4.41\n",
      "10. Oscar and Lucinda (a.k.a. Oscar & Lucinda) (1997) - Predicted rating: 4.41\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
